{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import dlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.spatial import distance as dist\n",
    "\n",
    "from io import BytesIO\n",
    "from IPython.display import clear_output, Image, display\n",
    "from PIL import Image as Img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padronizar_imagem(frame):\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    frame = cv2.resize(frame, (500, 400))\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exibir_video(frame):\n",
    "    img = Img.fromarray(frame, \"RGB\")\n",
    "    buffer = BytesIO()\n",
    "    img.save(buffer, format=\"JPEG\")\n",
    "    display(Image(data=buffer.getvalue()))\n",
    "    clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "classificador_dlib_68_path = \"classificadores/shape_predictor_68_face_landmarks.dat\"\n",
    "classificador_dlib = dlib.shape_predictor(classificador_dlib_68_path)\n",
    "detector_face = dlib.get_frontal_face_detector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def anotar_rosto(imagem):\n",
    "    retangulos = detector_face(imagem, 1)\n",
    "    \n",
    "    if len(retangulos) == 0:\n",
    "        return None\n",
    "    \n",
    "    for k, d in enumerate(retangulos):\n",
    "        cv2.rectangle(imagem, (d.left(), d.top()), (d.right(), d.bottom()), (255, 255, 0), 2)\n",
    "    \n",
    "    return imagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video terminado\n"
     ]
    }
   ],
   "source": [
    "video = cv2.VideoCapture(\"videos/expressoes.mov\")\n",
    "\n",
    "try:\n",
    "    while(True):\n",
    "        captura_ok, frame = video.read()\n",
    "        if captura_ok:\n",
    "            frame = padronizar_imagem(frame)\n",
    "            frame = anotar_rosto(frame)\n",
    "            exibir_video(frame)\n",
    "except KeyboardInterrupt:\n",
    "    video.release()\n",
    "    print(\"Interrompido\")\n",
    "except AttributeError or TypeError:\n",
    "    print(\"Video terminado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pontos_marcos_faciais(imagem):\n",
    "    retangulos = detector_face(imagem, 1)\n",
    "    \n",
    "    if len(retangulos) == 0:\n",
    "        return None\n",
    "    \n",
    "    marcos = []\n",
    "    \n",
    "    for ret in retangulos:\n",
    "        marcos.append(np.matrix([[p.x, p.y] for p in classificador_dlib(imagem,ret).parts()]))\n",
    "    \n",
    "    return marcos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def anotar_marcos_faciais(imagem, marcos):\n",
    "    \n",
    "    for marco in marcos:\n",
    "        for idx, ponto in enumerate(marco):\n",
    "            centro = (ponto[0,0], ponto[0,1])\n",
    "            cv2.circle(imagem, centro, 3, (255,255,0), -1)\n",
    "            #cv2.putText(imagem, str(idx), centro, cv2.FONT_HERSHEY_SIMPLEX, 0.8,\n",
    "            #           (255,255,255), 2)\n",
    "    \n",
    "    return imagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interrompido\n"
     ]
    }
   ],
   "source": [
    "video = cv2.VideoCapture(\"videos/expressoes.mov\")\n",
    "\n",
    "try:\n",
    "    while(True):\n",
    "        captura_ok, frame = video.read()\n",
    "        if captura_ok:\n",
    "            frame = padronizar_imagem(frame)\n",
    "            marcos = pontos_marcos_faciais(frame)\n",
    "            frame = anotar_marcos_faciais(frame,marcos)\n",
    "            exibir_video(frame)\n",
    "except KeyboardInterrupt:\n",
    "    video.release()\n",
    "    print(\"Interrompido\")\n",
    "except AttributeError or TypeError:\n",
    "    print(\"Video terminado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FACE = list(range(17, 68))\n",
    "FACE_COMPLETA = list(range(0, 68))\n",
    "LABIO = list(range(48, 61))\n",
    "SOMBRANCELHA_DIRETA = list(range(17, 22))\n",
    "SOMBRANCELHA_ESQUERDA = list(range(22, 27))\n",
    "OLHO_DIREITO = list(range(36,42))\n",
    "OLHO_ESQUERDO = list(range(42,48))\n",
    "NARIZ = list(range(27,35))\n",
    "MANDIBULA = list(range(0,17))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def anotar_marcos_casca_convexa_boca(imagem, marcos):\n",
    "    retangulos = detector_face(imagem, 1)\n",
    "    \n",
    "    if len(retangulos) == 0:\n",
    "        return None\n",
    "    \n",
    "    for idx, ret in enumerate(retangulos):\n",
    "        marco = marcos[idx]\n",
    "        \n",
    "        pontos = cv2.convexHull(marco[LABIO])\n",
    "        cv2.drawContours(imagem, [pontos], 0, (0,255,0), 2)\n",
    "\n",
    "    return imagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aspecto_razao_boca(pontos_boca):\n",
    "    a = dist.euclidean(pontos_boca[3], pontos_boca[9])\n",
    "    b = dist.euclidean(pontos_boca[2], pontos_boca[10])\n",
    "    c = dist.euclidean(pontos_boca[4], pontos_boca[8])\n",
    "    d = dist.euclidean(pontos_boca[0], pontos_boca[6])\n",
    "    \n",
    "    aspecto_razao = (a + b + c)/(3.0*d)\n",
    "    \n",
    "    return aspecto_razao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video = cv2.VideoCapture(\"videos/expressoes.mov\")\n",
    "\n",
    "try:\n",
    "    while(True):\n",
    "        captura_ok, frame = video.read()\n",
    "        if captura_ok:\n",
    "            frame = padronizar_imagem(frame)\n",
    "            marcos = pontos_marcos_faciais(frame)\n",
    "            frame = anotar_marcos_casca_convexa_boca(frame,marcos)\n",
    "            exibir_video(frame)\n",
    "except KeyboardInterrupt:\n",
    "    video.release()\n",
    "    print(\"Interrompido\")\n",
    "\n",
    "except AttributeError or TypeError:\n",
    "    print(\"Video terminado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def anotar_marcos_casca_convexa_olhos(imagem, marcos):\n",
    "    retangulos = detector_face(imagem, 1)\n",
    "    \n",
    "    if len(retangulos) == 0:\n",
    "        return None\n",
    "    \n",
    "    for idx, ret in enumerate(retangulos):\n",
    "        marco = marcos[idx]\n",
    "        \n",
    "        pontos = cv2.convexHull(marco[OLHO_ESQUERDO])\n",
    "        cv2.drawContours(imagem, [pontos], 0, (0,255,0), 2)\n",
    "        \n",
    "        pontos = cv2.convexHull(marco[OLHO_DIREITO])\n",
    "        cv2.drawContours(imagem, [pontos], 0, (0,255,0), 2)\n",
    "    \n",
    "    return imagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__call__(): incompatible function arguments. The following argument types are supported:\n    1. (self: _dlib_pybind11.fhog_object_detector, image: array, upsample_num_times: int=0) -> _dlib_pybind11.rectangles\n\nInvoked with: <_dlib_pybind11.fhog_object_detector object at 0x00000259D0746BB0>, None, 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[47], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m             marcos \u001b[38;5;241m=\u001b[39m pontos_marcos_faciais(frame)\n\u001b[0;32m      9\u001b[0m             frame \u001b[38;5;241m=\u001b[39m anotar_marcos_casca_convexa_boca(frame,marcos)\n\u001b[1;32m---> 10\u001b[0m             frame \u001b[38;5;241m=\u001b[39m \u001b[43manotar_marcos_casca_convexa_olhos\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmarcos\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m             exibir_video(frame)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n",
      "Cell \u001b[1;32mIn[46], line 2\u001b[0m, in \u001b[0;36manotar_marcos_casca_convexa_olhos\u001b[1;34m(imagem, marcos)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21manotar_marcos_casca_convexa_olhos\u001b[39m(imagem, marcos):\n\u001b[1;32m----> 2\u001b[0m     retangulos \u001b[38;5;241m=\u001b[39m \u001b[43mdetector_face\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimagem\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(retangulos) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m      5\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: __call__(): incompatible function arguments. The following argument types are supported:\n    1. (self: _dlib_pybind11.fhog_object_detector, image: array, upsample_num_times: int=0) -> _dlib_pybind11.rectangles\n\nInvoked with: <_dlib_pybind11.fhog_object_detector object at 0x00000259D0746BB0>, None, 1"
     ]
    }
   ],
   "source": [
    "video = cv2.VideoCapture(\"videos/expressoes.mov\")\n",
    "\n",
    "try:\n",
    "    while(True):\n",
    "        captura_ok, frame = video.read()\n",
    "        if captura_ok:\n",
    "            frame = padronizar_imagem(frame)\n",
    "            marcos = pontos_marcos_faciais(frame)\n",
    "            frame = anotar_marcos_casca_convexa_boca(frame,marcos)\n",
    "            frame = anotar_marcos_casca_convexa_olhos(frame,marcos)\n",
    "\n",
    "            exibir_video(frame)\n",
    "except KeyboardInterrupt:\n",
    "    video.release()\n",
    "    print(\"Interrompido\")\n",
    "\n",
    "except AttributeError or TypeError:\n",
    "    print(\"Video terminado\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
